# Drop labels we are uncertain about their validity
            if self.freqai_info["labeling_parameters"].get("drop_uncertain_labels", False):
                # X_train: Drop samples after last detected min / max
                # (because labels are not known for sure after)
                last_row_idx = y_train.last_valid_index()
                reduced_last_row_idx = y_train[y_train != "not_minmax"].last_valid_index()
                X_train = X_train.loc[:reduced_last_row_idx, :]  # Pandas DataFrame
                y_train = y_train.loc[:reduced_last_row_idx]  # Pandas Series
                rows_dropped = last_row_idx - reduced_last_row_idx
                weight_train = weight_train[:len(weight_train) - rows_dropped]  # Numpy array
                logger.info(f"Dropping {rows_dropped} rows from train after last known min/max.")

                # X_test: Drop samples before first detected min / max
                # (because labels are not known for sure before)
                first_row_idx = y_test.first_valid_index()
                reduced_first_row_idx = y_test[y_test != "not_minmax"].first_valid_index()
                X_test = X_test.loc[reduced_first_row_idx:, :]  # Pandas DataFrame
                y_test = y_test.loc[reduced_first_row_idx:]  # Pandas Series
                rows_dropped = reduced_first_row_idx - first_row_idx
                weight_test = weight_test[rows_dropped:]  # Numpy array
                logger.info(f"Dropping {rows_dropped} rows from test before first known min/max.")
